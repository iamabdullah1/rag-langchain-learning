{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad41bb93",
   "metadata": {},
   "source": [
    "## ü§î What are Embeddings?\n",
    "\n",
    "**Embeddings** convert text into a list of numbers (called a **vector**) that represents the text's **meaning**.\n",
    "\n",
    "```\n",
    "\"I love dogs\"     ‚Üí  [0.2, -0.5, 0.8, 0.1, ...]  (384 numbers)\n",
    "\"I adore puppies\" ‚Üí  [0.3, -0.4, 0.7, 0.2, ...]  (similar numbers!)\n",
    "\"I hate rain\"     ‚Üí  [-0.8, 0.3, -0.2, 0.9, ...] (different numbers)\n",
    "```\n",
    "\n",
    "**Key insight:** Similar meanings ‚Üí Similar numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bee47",
   "metadata": {},
   "source": [
    "## Why Do We Need Embeddings?\n",
    "\n",
    "**Problem:** Computers can't understand text directly.\n",
    "\n",
    "```\n",
    "‚ùå Computer can't do: \"qualitative research\" ‚âà \"interview methods\"\n",
    "‚úÖ Computer can do:   [0.2, 0.5, ...] ‚âà [0.3, 0.4, ...]  (number comparison!)\n",
    "```\n",
    "\n",
    "**Solution:** Convert text to numbers, then compare numbers!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582b24a",
   "metadata": {},
   "source": [
    "## Step 1: Set Up (Load chunks from previous notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99705f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents and create chunks (from Notebooks 1 & 2)\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Set up paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_folder = os.path.join(project_root, 'data')\n",
    "\n",
    "# Load PDFs\n",
    "print(\"üìö Loading documents...\")\n",
    "all_pages = []\n",
    "for pdf_name in os.listdir(data_folder):\n",
    "    if pdf_name.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(os.path.join(data_folder, pdf_name))\n",
    "        all_pages.extend(loader.load())\n",
    "\n",
    "# Split into chunks\n",
    "print(\"‚úÇÔ∏è Creating chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(all_pages)\n",
    "\n",
    "print(f\"\\n‚úÖ Ready! {len(chunks)} chunks to embed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ed3e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Load the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the embedding model\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"üî¢ Loading embedding model...\")\n",
    "print(\"   Model: all-MiniLM-L6-v2\")\n",
    "print(\"   (This is a free, local model - no API key needed!)\\n\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embedding model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a429b",
   "metadata": {},
   "source": [
    "### üí° About the Model\n",
    "\n",
    "**all-MiniLM-L6-v2** is:\n",
    "- Free and open source\n",
    "- Runs locally (no internet needed after download)\n",
    "- Fast and efficient\n",
    "- Creates 384-dimensional vectors\n",
    "\n",
    "**Other options:**\n",
    "- `text-embedding-ada-002` (OpenAI) - Better quality, but costs money\n",
    "- `all-mpnet-base-v2` - Higher quality, but slower\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15aaef3",
   "metadata": {},
   "source": [
    "## Step 3: Create Your First Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ce8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding for a simple text\n",
    "sample_text = \"qualitative research methods\"\n",
    "\n",
    "print(f\"üìù Text: '{sample_text}'\")\n",
    "print(\"\\nüîÑ Converting to embedding...\\n\")\n",
    "\n",
    "# Create the embedding\n",
    "vector = embeddings.embed_query(sample_text)\n",
    "\n",
    "print(f\"‚úÖ Created embedding!\")\n",
    "print(f\"\\nüìä Vector details:\")\n",
    "print(f\"   Length: {len(vector)} numbers\")\n",
    "print(f\"   First 5 numbers: {[round(v, 4) for v in vector[:5]]}\")\n",
    "print(f\"   Last 5 numbers:  {[round(v, 4) for v in vector[-5:]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f0682",
   "metadata": {},
   "source": [
    "### üí° What Just Happened?\n",
    "\n",
    "```\n",
    "\"qualitative research methods\"\n",
    "              ‚Üì\n",
    "        Embedding Model\n",
    "              ‚Üì\n",
    "[0.023, -0.051, 0.089, ..., 0.012]  ‚Üê 384 numbers!\n",
    "```\n",
    "\n",
    "These 384 numbers encode the **meaning** of the text in a way computers can process.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444598a",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate how similar two vectors are (0 to 1).\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Test with similar and different texts\n",
    "texts = [\n",
    "    \"qualitative research methods\",\n",
    "    \"interview techniques in research\",  # Similar meaning\n",
    "    \"data analysis approaches\",           # Somewhat similar\n",
    "    \"the weather is nice today\"           # Very different\n",
    "]\n",
    "\n",
    "# Create embeddings for all texts\n",
    "print(\"üîç Comparing text similarity:\\n\")\n",
    "print(f\"üìù Base text: '{texts[0]}'\\n\")\n",
    "\n",
    "base_vector = embeddings.embed_query(texts[0])\n",
    "\n",
    "for i, text in enumerate(texts[1:], 1):\n",
    "    vector = embeddings.embed_query(text)\n",
    "    similarity = cosine_similarity(base_vector, vector)\n",
    "    \n",
    "    # Visual bar\n",
    "    bar_length = int(similarity * 20)\n",
    "    bar = \"‚ñà\" * bar_length + \"‚ñë\" * (20 - bar_length)\n",
    "    \n",
    "    print(f\"   '{text}'\")\n",
    "    print(f\"   Similarity: {bar} {similarity:.2%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e0358",
   "metadata": {},
   "source": [
    "### üí° Understanding Cosine Similarity\n",
    "\n",
    "**Cosine similarity** measures how \"aligned\" two vectors are:\n",
    "\n",
    "| Score | Meaning |\n",
    "|-------|----------|\n",
    "| 1.0 (100%) | Identical meaning |\n",
    "| 0.8+ | Very similar |\n",
    "| 0.5-0.8 | Somewhat related |\n",
    "| < 0.5 | Different topics |\n",
    "\n",
    "This is how we find relevant chunks for a question!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53017723",
   "metadata": {},
   "source": [
    "## Step 5: Embed a Document Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed one of our actual chunks\n",
    "sample_chunk = chunks[0]\n",
    "\n",
    "print(\"üìÑ Sample Chunk:\")\n",
    "print(\"=\"*60)\n",
    "print(sample_chunk.page_content[:300] + \"...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create embedding\n",
    "chunk_vector = embeddings.embed_query(sample_chunk.page_content)\n",
    "\n",
    "print(f\"\\n‚úÖ Chunk embedded!\")\n",
    "print(f\"   Vector length: {len(chunk_vector)} numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1e2eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Batch Embedding (Multiple Texts at Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed multiple texts efficiently\n",
    "print(\"üî¢ Embedding multiple chunks at once...\\n\")\n",
    "\n",
    "# Take first 5 chunks as example\n",
    "sample_texts = [chunk.page_content for chunk in chunks[:5]]\n",
    "\n",
    "# Embed all at once (more efficient than one by one)\n",
    "vectors = embeddings.embed_documents(sample_texts)\n",
    "\n",
    "print(f\"‚úÖ Created {len(vectors)} embeddings!\")\n",
    "print(f\"\\nüìä Each vector has {len(vectors[0])} dimensions\")\n",
    "\n",
    "# Show the shape\n",
    "print(f\"\\nüîç Result shape: {len(vectors)} texts √ó {len(vectors[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77cc8a",
   "metadata": {},
   "source": [
    "### üí° embed_query vs embed_documents\n",
    "\n",
    "| Method | Use For | Example |\n",
    "|--------|---------|----------|\n",
    "| `embed_query(text)` | Single text (user's question) | \"What is coding?\" |\n",
    "| `embed_documents(list)` | Multiple texts (batch) | All your chunks |\n",
    "\n",
    "`embed_documents` is more efficient for many texts!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02c3bb",
   "metadata": {},
   "source": [
    "## üß™ Experiment: Find Similar Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78291c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually find the most similar chunk to a question\n",
    "question = \"What is qualitative data coding?\"\n",
    "\n",
    "print(f\"‚ùì Question: '{question}'\\n\")\n",
    "\n",
    "# Embed the question\n",
    "question_vector = embeddings.embed_query(question)\n",
    "\n",
    "# Embed first 20 chunks and find most similar\n",
    "print(\"üîç Searching through chunks...\\n\")\n",
    "\n",
    "similarities = []\n",
    "for i, chunk in enumerate(chunks[:20]):\n",
    "    chunk_vector = embeddings.embed_query(chunk.page_content)\n",
    "    sim = cosine_similarity(question_vector, chunk_vector)\n",
    "    similarities.append((i, sim, chunk))\n",
    "\n",
    "# Sort by similarity\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show top 3\n",
    "print(\"üìä Top 3 Most Similar Chunks:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (idx, sim, chunk) in enumerate(similarities[:3], 1):\n",
    "    print(f\"\\n#{i} Similarity: {sim:.2%}\")\n",
    "    print(f\"   {chunk.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee84e20",
   "metadata": {},
   "source": [
    "### üí° This is Exactly How RAG Works!\n",
    "\n",
    "```\n",
    "1. User asks: \"What is qualitative coding?\"\n",
    "                    ‚Üì\n",
    "2. Convert question to vector\n",
    "                    ‚Üì\n",
    "3. Compare with all chunk vectors\n",
    "                    ‚Üì\n",
    "4. Return most similar chunks\n",
    "                    ‚Üì\n",
    "5. Send chunks to AI for answer\n",
    "```\n",
    "\n",
    "In the next notebook, we'll store these vectors in a database for fast searching!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816ac6a",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **What embeddings are** - Converting text to meaningful numbers\n",
    "2. **Why we need them** - Computers can compare numbers, not text\n",
    "3. **HuggingFace embeddings** - Free, local embedding model\n",
    "4. **Cosine similarity** - Measuring how similar two texts are\n",
    "5. **Finding similar chunks** - The core of RAG retrieval\n",
    "\n",
    "## ‚û°Ô∏è Next Step\n",
    "\n",
    "In **Notebook 4: Vector Store**, you'll learn how to store these embeddings in ChromaDB for fast, efficient searching.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Components:**\n",
    "- `embeddings` - The HuggingFace embedding model\n",
    "- `chunks` - Your document chunks ready to be stored"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
